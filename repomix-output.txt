This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-27T11:41:44.303Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
.gitignore
event_fetcher.py
graphql_query_template.json
README.md
requirements.txt

================================================================
Repository Files
================================================================

================
File: .gitignore
================
venvs
*.csv

================
File: event_fetcher.py
================
import requests
import json
import time
import csv
import sys
import argparse
from datetime import datetime, timedelta

URL = 'https://ra.co/graphql'
HEADERS = {
    'Content-Type': 'application/json',
    'Referer': 'https://ra.co/events/uk/london',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:106.0) Gecko/20100101 Firefox/106.0'
}
QUERY_TEMPLATE_PATH = "graphql_query_template.json"
DELAY = 1  # Adjust this value as needed


class EventFetcher:
    """
    A class to fetch and print event details from RA.co
    """

    def __init__(self, areas, listing_date_gte, listing_date_lte):
        self.payload = self.generate_payload(areas, listing_date_gte, listing_date_lte)

    @staticmethod
    def generate_payload(areas, listing_date_gte, listing_date_lte):
        """
        Generate the payload for the GraphQL request.

        :param areas: The area code to filter events.
        :param listing_date_gte: The start date for event listings (inclusive).
        :param listing_date_lte: The end date for event listings (inclusive).
        :return: The generated payload.
        """
        with open(QUERY_TEMPLATE_PATH, "r") as file:
            payload = json.load(file)

        payload["variables"]["filters"]["areas"]["eq"] = areas
        payload["variables"]["filters"]["listingDate"]["gte"] = listing_date_gte
        payload["variables"]["filters"]["listingDate"]["lte"] = listing_date_lte

        return payload

    def get_events(self, page_number):
        """
        Fetch events for the given page number.

        :param page_number: The page number for event listings.
        :return: A list of events.
        """
        self.payload["variables"]["page"] = page_number
        response = requests.post(URL, headers=HEADERS, json=self.payload)

        try:
            response.raise_for_status()
            data = response.json()
        except (requests.exceptions.RequestException, ValueError):
            print(f"Error: {response.status_code}")
            return []

        if 'data' not in data:
            print(f"Error: {data}")
            return []

        return data["data"]["eventListings"]["data"]

    @staticmethod
    def print_event_details(events):
        """
        Print the details of the events.

        :param events: A list of events.
        """
        for event in events:
            event_data = event["event"]
            print(f"Event name: {event_data['title']}")
            print(f"Date: {event_data['date']}")
            print(f"Start Time: {event_data['startTime']}")
            print(f"End Time: {event_data['endTime']}")
            print(f"Artists: {[artist['name'] for artist in event_data['artists']]}")
            print(f"Venue: {event_data['venue']['name']}")
            print(f"Event URL: {event_data['contentUrl']}")
            print(f"Number of guests attending: {event_data['attending']}")
            print("-" * 80)

    def fetch_and_print_all_events(self):
        """
        Fetch and print all events.
        """
        page_number = 1

        while True:
            events = self.get_events(page_number)

            if not events:
                break

            self.print_event_details(events)
            page_number += 1
            time.sleep(DELAY)

    def fetch_all_events(self):
        """
        Fetch all events and return them as a list.

        :return: A list of all events.
        """
        all_events = []
        page_number = 1

        while True:
            events = self.get_events(page_number)

            if not events:
                break

            all_events.extend(events)
            page_number += 1
            time.sleep(DELAY)

        return all_events

    def save_events_to_csv(self, events, output_file="events.csv"):
        """
        Save events to a CSV file.

        :param events: A list of events.
        :param output_file: The output file path. (default: "events.csv")
        """
        with open(output_file, "w", newline="", encoding="utf-8") as file:
            writer = csv.writer(file)
            writer.writerow(["Event name", "Date", "Start Time", "End Time", "Artists",
                             "Venue", "Event URL", "Number of guests attending"])

            for event in events:
                event_data = event["event"]
                writer.writerow([event_data['title'], event_data['date'], event_data['startTime'],
                                 event_data['endTime'], ', '.join([artist['name'] for artist in event_data['artists']]),
                                 event_data['venue']['name'], event_data['contentUrl'], event_data['attending']])


def main():
    parser = argparse.ArgumentParser(description="Fetch events from ra.co and save them to a CSV file.")
    parser.add_argument("areas", type=int, help="The area code to filter events.")
    parser.add_argument("start_date", type=str, help="The start date for event listings (inclusive, format: YYYY-MM-DD).")
    parser.add_argument("end_date", type=str, help="The end date for event listings (inclusive, format: YYYY-MM-DD).")
    parser.add_argument("-o", "--output", type=str, default="events.csv", help="The output file path (default: events.csv).")
    args = parser.parse_args()

    listing_date_gte = f"{args.start_date}T00:00:00.000Z"
    listing_date_lte = f"{args.end_date}T23:59:59.999Z"

    event_fetcher = EventFetcher(args.areas, listing_date_gte, listing_date_lte)

    all_events = []
    current_start_date = datetime.strptime(args.start_date, "%Y-%m-%d")

    while current_start_date <= datetime.strptime(args.end_date, "%Y-%m-%d"):
        listing_date_gte = current_start_date.strftime("%Y-%m-%dT00:00:00.000Z")
        event_fetcher.payload = event_fetcher.generate_payload(args.areas, listing_date_gte, listing_date_lte)
        events = event_fetcher.fetch_all_events()
        all_events.extend(events)
        current_start_date += timedelta(days=len(events))

    event_fetcher.save_events_to_csv(all_events, args.output)


if __name__ == "__main__":
    main()

================
File: graphql_query_template.json
================
{
    "operationName": "GET_EVENT_LISTINGS",
    "variables": {
        "filters": {
            "areas": {"eq": "__AREAS__"},
            "listingDate": {
                "gte": "__LISTING_DATE_GTE__",
                "lte": "__LISTING_DATE_LTE__"
            }
        },
        "filterOptions": {"genre": true},
        "pageSize": 20,
        "page": 1
    },
    "query": "query GET_EVENT_LISTINGS($filters: FilterInputDtoInput, $filterOptions: FilterOptionsInputDtoInput, $page: Int, $pageSize: Int) {eventListings(filters: $filters, filterOptions: $filterOptions, pageSize: $pageSize, page: $page) {data {id listingDate event {...eventListingsFields artists {id name __typename} __typename} __typename} filterOptions {genre {label value __typename} __typename} totalResults __typename}}fragment eventListingsFields on Event {id date startTime endTime title contentUrl flyerFront isTicketed attending queueItEnabled newEventForm images {id filename alt type crop __typename} pick {id blurb __typename} venue {id name contentUrl live __typename} __typename}"
}

================
File: README.md
================
# RA.co Event Fetcher

A Python tool to fetch event data from the RA.co GraphQL API and save it as a CSV or JSON file. This tool accepts event area, start date, and end date as command-line arguments and saves the fetched events to a CSV file by default.

## Requirements

- Python 3.6 or higher
- requests library (pip install requests)
- pandas library (pip install pandas)

## Installation

1. Clone the repository or download the source code.
2. Run pip install -r requirements.txt to install the required libraries.

## Usage

### Command-Line Arguments

- `areas`: The area code to filter events.
- `start_date`: The start date for event listings (inclusive, format: `YYYY-MM-DD`).
- `end_date`: The end date for event listings (inclusive, format: `YYYY-MM-DD`).
- `-o` or `--output`: (Optional) The output file path (default: `events.csv`).

### Example

To fetch events for area 13 between April 23, 2023, and April 29, 2023, and save them to a CSV file named `events.csv`, run the following command:

```
python event_fetcher.py 13 2023-04-23 2023-04-29 -o events.csv
```

## Output

The fetched events will be saved to the specified output file (CSV by default) with the following columns:

- Event name
- Date
- Start Time
- End Time
- Artists
- Venue
- Event URL
- Number of guests attending

================
File: requirements.txt
================
certifi==2022.12.7
charset-normalizer==3.1.0
idna==3.4
requests==2.28.2
urllib3==1.26.15
